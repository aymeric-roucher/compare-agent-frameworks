{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autogen\n",
    "\n",
    "In [autogen](https://github.com/microsoft/autogen) I didn't success to make any web-browsing system, either with the [built-in example from the doc](https://microsoft.github.io/autogen/0.2/docs/notebooks/agentchat_groupchat_research/), or a multi-agent system with a [custom tool](https://microsoft.github.io/autogen/0.2/docs/tutorial/tool-use/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "config_list_gpt4 = [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is equivalent to:\n",
    "# from transformers.agents import DuckDuckGoSearchTool\n",
    "\n",
    "\n",
    "def search(query: str) -> str:\n",
    "    try:\n",
    "        from duckduckgo_search import DDGS\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"You must install package `duckduckgo_search` to run this tool: for instance run `pip install duckduckgo-search`.\"\n",
    "        )\n",
    "    results = DDGS().text(query, max_results=7)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_config = {\n",
    "    \"cache_seed\": 42,  # change the cache_seed for different trials\n",
    "    \"temperature\": 0,\n",
    "    \"config_list\": config_list_gpt4,\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "# This one often causes the code to run on infinite loop of asking the admin his opinion\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"Admin\",\n",
    "    system_message=\"A human admin.\",\n",
    "    code_execution_config=False,\n",
    ")\n",
    "engineer = autogen.AssistantAgent(\n",
    "    name=\"Engineer\",\n",
    "    llm_config=gpt4_config,\n",
    "    system_message=\"\"\"Engineer. You follow an approved plan. You write python/shell code to solve tasks. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.\n",
    "Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.\n",
    "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "\"\"\",\n",
    ")\n",
    "websearch = autogen.AssistantAgent(\n",
    "    name=\"Web searcher\",\n",
    "    llm_config=gpt4_config,\n",
    "    system_message=\"\"\"Web searcher.You can search the web to find papers. You don't write code.\"\"\",\n",
    ")\n",
    "# websearch.register_for_llm(name=\"search\", description=\"A simple google search\")(search)\n",
    "\n",
    "# # Why should we need this second line? Strange\n",
    "# user_proxy.register_for_execution(name=\"search\")(search)\n",
    "\n",
    "# Since the above two lines didn'y work, let's try another way from the doc\n",
    "from autogen import register_function\n",
    "\n",
    "register_function(\n",
    "    search,\n",
    "    caller=websearch,  # The assistant agent can suggest calls to the calculator.\n",
    "    executor=user_proxy,  # The user proxy agent can execute the calculator calls.\n",
    "    name=\"search\",  # By default, the function name is used as the tool name.\n",
    "    description=\"A simple google search\",  # A description of the tool.\n",
    ")\n",
    "\n",
    "\n",
    "executor = autogen.UserProxyAgent(\n",
    "    name=\"Executor\",\n",
    "    system_message=\"Executor. Execute the code written by the engineer and report the result.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 3,\n",
    "        \"work_dir\": \"paper\",\n",
    "        \"use_docker\": False,\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents=[engineer, executor, websearch], messages=[], max_round=50\n",
    ")\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=gpt4_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search': <function __main__.search(query: str) -> str>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.function_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "What's the current age of the Pope, power 0.82? Use web search first\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Web searcher\n",
      "\u001b[0m\n",
      "\u001b[33mWeb searcher\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_w2JoVM3ewqFZhad5enewHwkz): search *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"query\": \"current age of the Pope\"\n",
      "}\n",
      "\u001b[32m***********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No agent can execute the function search. Please check the function_map of the agents.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43muser_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43mWhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms the current age of the Pope, power 0.82? Use web search first\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/compare-agents/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:1106\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m         msg2send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_init_message(message, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1106\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summarize_chat(\n\u001b[1;32m   1108\u001b[0m     summary_method,\n\u001b[1;32m   1109\u001b[0m     summary_args,\n\u001b[1;32m   1110\u001b[0m     recipient,\n\u001b[1;32m   1111\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m   1112\u001b[0m )\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "File \u001b[0;32m~/venv/compare-agents/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:741\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    739\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[0;32m--> 741\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    744\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    745\u001b[0m     )\n",
      "File \u001b[0;32m~/venv/compare-agents/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:906\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 906\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/venv/compare-agents/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:2060\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   2058\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 2060\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2061\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[1;32m   2062\u001b[0m         log_event(\n\u001b[1;32m   2063\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2064\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2068\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[1;32m   2069\u001b[0m         )\n",
      "File \u001b[0;32m~/venv/compare-agents/lib/python3.12/site-packages/autogen/agentchat/groupchat.py:1169\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# select the next speaker\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     speaker \u001b[38;5;241m=\u001b[39m \u001b[43mgroupchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n\u001b[1;32m   1171\u001b[0m         iostream \u001b[38;5;241m=\u001b[39m IOStream\u001b[38;5;241m.\u001b[39mget_default()\n",
      "File \u001b[0;32m~/venv/compare-agents/lib/python3.12/site-packages/autogen/agentchat/groupchat.py:555\u001b[0m, in \u001b[0;36mGroupChat.select_speaker\u001b[0;34m(self, last_speaker, selector)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Select the next speaker (with requery).\"\"\"\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;66;03m# Prepare the list of available agents and select an agent if selection method allows (non-auto)\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m selected_agent, agents, messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_and_select_agents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_speaker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_agent:\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m selected_agent\n",
      "File \u001b[0;32m~/venv/compare-agents/lib/python3.12/site-packages/autogen/agentchat/groupchat.py:502\u001b[0m, in \u001b[0;36mGroupChat._prepare_and_select_agents\u001b[0;34m(self, last_speaker)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m agents[\u001b[38;5;241m0\u001b[39m], agents, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m agents:\n\u001b[0;32m--> 502\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo agent can execute the function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(funcs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the function_map of the agents.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m             )\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# remove the last speaker from the list to avoid selecting the same speaker if allow_repeat_speaker is False\u001b[39;00m\n\u001b[1;32m    507\u001b[0m agents \u001b[38;5;241m=\u001b[39m [agent \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m agents \u001b[38;5;28;01mif\u001b[39;00m agent \u001b[38;5;241m!=\u001b[39m last_speaker] \u001b[38;5;28;01mif\u001b[39;00m allow_repeat_speaker \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m agents\n",
      "\u001b[0;31mValueError\u001b[0m: No agent can execute the function search. Please check the function_map of the agents."
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"\"\"\n",
    "What's the current age of the Pope, power 0.82? Use web search first\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution feedback\n",
    "\n",
    "This quickly became a shitshow, with many turns spent in vain while the manager agent (of which we don't see the decisions) misallocating next turns to various members of the team.\n",
    "```bash\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: Engineer\n",
    "\n",
    "Engineer (to chat_manager):\n",
    "\n",
    "I apologize for the confusion. It seems that the `feedparser` library is also not available in this environment. \n",
    "\n",
    "Unfortunately, without the ability to install additional libraries, we are limited in our ability to interact with the Arxiv API or RSS feed directly from this environment.\n",
    "\n",
    "However, I can provide a Python script that you can run in your local environment to fetch the papers from Arxiv and create a markdown table. You will need to install the `arxiv` and `pandas` libraries to run this script.\n",
    "\n",
    "Here is the script:\n",
    "\n",
    "```python\n",
    "import arxiv\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Define the search query\n",
    "query = \"all:LLM\"\n",
    "\n",
    "# Define the time range (last week)\n",
    "start_time = datetime.datetime.now() - datetime.timedelta(weeks=1)\n",
    "start_time_str = start_time.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "# Fetch the papers\n",
    "papers = arxiv.Search(\n",
    "    query=query,\n",
    "    sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "    sort_order=arxiv.SortOrder.Descending,\n",
    "    start_time=start_time_str\n",
    ").results()\n",
    "\n",
    "# Create a DataFrame to store the papers\n",
    "df = pd.DataFrame(columns=[\"Title\", \"Authors\", \"Summary\", \"URL\"])\n",
    "\n",
    "# Add the papers to the DataFrame\n",
    "for paper in papers:\n",
    "    df = df.append({\n",
    "        \"Title\": paper.title,\n",
    "        \"Authors\": ', '.join(author.name for author in paper.authors),\n",
    "        \"Summary\": paper.summary,\n",
    "        \"URL\": paper.entry_id\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Convert the DataFrame to a markdown table\n",
    "markdown_table = df.to_markdown()\n",
    "\n",
    "# Print the markdown table\n",
    "print(markdown_table)\n",
    "```\n",
    "\n",
    "To run this script, you will need to install the `arxiv` and `pandas` libraries. You can do this by running `pip install arxiv pandas` in your command line.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: Scientist\n",
    "\n",
    "Scientist (to chat_manager):\n",
    "\n",
    "I'm sorry for the confusion, but as a text-based AI model, I don't have the ability to install packages or run scripts in a local environment. However, I can guide you on how to do it.\n",
    "\n",
    "Here's how you can run the script provided by the Engineer:\n",
    "\n",
    "1. Open a terminal on your computer.\n",
    "\n",
    "2. If you don't have Python installed, download and install it from the official website: https://www.python.org/downloads/\n",
    "\n",
    "3. Install the `arxiv` and `pandas` libraries by running the following command in your terminal:\n",
    "   ```\n",
    "   pip install arxiv pandas\n",
    "   ```\n",
    "\n",
    "4. Create a new Python file (for example, `fetch_papers.py`) and copy the script into this file.\n",
    "\n",
    "5. Run the script by running the following command in your terminal:\n",
    "   ```\n",
    "   python fetch_papers.py\n",
    "   ```\n",
    "\n",
    "The script will print a markdown table of the papers on LLM applications published in the last week. The table will have columns for the title, authors, summary, and URL of each paper.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: Critic\n",
    "\n",
    "Critic (to chat_manager):\n",
    "\n",
    "The plan and the code provided by the Engineer and Scientist are correct. However, it's important to note that the code can't be executed in this environment due to the lack of necessary libraries. The Scientist has provided a detailed guide on how to run the script in a local environment. Please follow these instructions to execute the script.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: Admin\n",
    "\n",
    "\n",
    ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
    "\n",
    ">>>>>>>> USING AUTO REPLY...\n",
    "Admin (to chat_manager):\n",
    "\n",
    "\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: Scientist\n",
    "\n",
    "Scientist (to chat_manager):\n",
    "\n",
    "As an AI model, I don't have the ability to execute scripts or install packages. However, I can provide guidance and instructions. Please follow the steps provided by the Scientist to run the script in your local environment.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: Admin\n",
    "\n",
    "\n",
    ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
    "\n",
    ">>>>>>>> USING AUTO REPLY...\n",
    "Admin (to chat_manager):\n",
    "\n",
    "\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: Engineer\n",
    "\n",
    "Engineer (to chat_manager):\n",
    "\n",
    "I apologize for the confusion. As an AI model, I don't have the ability to execute scripts or install packages. However, I can provide guidance and instructions. Please follow the steps provided by the Scientist to run the script in your local environment.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: Admin\n",
    "\n",
    "\n",
    ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
    "\n",
    ">>>>>>>> USING AUTO REPLY...\n",
    "Admin (to chat_manager):\n",
    "\n",
    "\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: Scientist\n",
    "\n",
    "Scientist (to chat_manager):\n",
    "\n",
    "As an AI model, I don't have the ability to execute scripts or install packages. However, I can provide guidance and instructions. Please follow the steps provided by the Scientist to run the script in your local environment.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: Engineer\n",
    "\n",
    "Engineer (to chat_manager):\n",
    "\n",
    "As an AI model, I don't have the ability to execute scripts or install packages. However, I can provide guidance and instructions. Please follow the steps provided by the Scientist to run the script in your local environment.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: Critic\n",
    "\n",
    "Critic (to chat_manager):\n",
    "\n",
    "The plan and the code provided by the Engineer and Scientist are correct. However, it's important to note that the code can't be executed in this environment due to the lack of necessary libraries. The Scientist has provided a detailed guide on how to run the script in a local environment. Please follow these instructions to execute the script.\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "Next speaker: Admin\n",
    "```\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second try\n",
    "\n",
    "Let's simplify the team to make it more efficient.\n",
    "\n",
    "I removed all agents except useful ones and tried to add the web search tool to them:\n",
    "I get error: `ValueError: No agent can execute the function search. Please check the function_map of the agents.`\n",
    "\n",
    "Although the function is well defined in the agent's `function_map`:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "So the mystery continues. Anyway I've got some good ideas from autogen already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'calculator': <function __main__.calculator(a: int, b: int, operator: Annotated[Literal['+', '-', '*', '/'], 'operator']) -> int>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "Operator = Literal[\"+\", \"-\", \"*\", \"/\"]\n",
    "\n",
    "\n",
    "def calculator(a: int, b: int, operator: Annotated[Operator, \"operator\"]) -> int:\n",
    "    if operator == \"+\":\n",
    "        return a + b\n",
    "    elif operator == \"-\":\n",
    "        return a - b\n",
    "    elif operator == \"*\":\n",
    "        return a * b\n",
    "    elif operator == \"/\":\n",
    "        return int(a / b)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid operator\")\n",
    "\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "# Let's first define the assistant agent that suggests tool calls.\n",
    "assistant = ConversableAgent(\n",
    "    name=\"Assistant\",\n",
    "    system_message=\"You are a helpful AI assistant. \"\n",
    "    \"You can help with simple calculations. \"\n",
    "    \"Return 'TERMINATE' when the task is done.\",\n",
    "    llm_config={\n",
    "        \"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]\n",
    "    },\n",
    ")\n",
    "\n",
    "# The user proxy agent is used for interacting with the assistant agent\n",
    "# and executes tool calls.\n",
    "user_proxy = ConversableAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=False,\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None\n",
    "    and \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Register the tool signature with the assistant agent.\n",
    "assistant.register_for_llm(name=\"calculator\", description=\"A simple calculator\")(\n",
    "    calculator\n",
    ")\n",
    "\n",
    "# Register the tool function with the user proxy agent.\n",
    "user_proxy.register_for_execution(name=\"calculator\")(calculator)\n",
    "\n",
    "user_proxy.function_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "What is (44232 + 13312 / (232 - 32)) * 5?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_v7VMeSzM5RWZ6XHXWK3zu6ou): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"a\": 232,\n",
      "  \"b\": 32,\n",
      "  \"operator\": \"-\"\n",
      "}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_v7VMeSzM5RWZ6XHXWK3zu6ou) *****\u001b[0m\n",
      "200\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_npRmhUCUfgMFNCG9c8Gwz9A7): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"a\": 13312,\n",
      "  \"b\": 200,\n",
      "  \"operator\": \"/\"\n",
      "}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_npRmhUCUfgMFNCG9c8Gwz9A7) *****\u001b[0m\n",
      "66\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_vOckSBOeoAjR8DKBqwHlcvAZ): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"a\": 44232,\n",
      "  \"b\": 66,\n",
      "  \"operator\": \"+\"\n",
      "}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_vOckSBOeoAjR8DKBqwHlcvAZ) *****\u001b[0m\n",
      "44298\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_cWfU1xsZFw5wcTwbmzgbOI5c): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"a\": 44298,\n",
      "  \"b\": 5,\n",
      "  \"operator\": \"*\"\n",
      "}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_cWfU1xsZFw5wcTwbmzgbOI5c) *****\u001b[0m\n",
      "221490\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "The result of the calculation (44232 + 13312 / (232 - 32)) * 5 is 221490.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = user_proxy.initiate_chat(\n",
    "    assistant, message=\"What is (44232 + 13312 / (232 - 32)) * 5?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compare-agents",
   "language": "python",
   "name": "compare-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
